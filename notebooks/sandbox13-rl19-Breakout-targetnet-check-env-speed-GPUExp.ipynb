{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, episode,step, info=\"\"):\n",
    "    plt.figure(99999,figsize=[8,6])\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"episode: {} step: {} \".format(episode,step))\n",
    "    #plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device=torch.device(\"cuda:4\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PARAMS ######\n",
    "learning_rate = 0.01\n",
    "num_episodes = 5000\n",
    "gamma=0.999999\n",
    "#gamma=0.85\n",
    "egreedy = 0.1\n",
    "egreedy_final = 0.01\n",
    "egreedy_decay = 500\n",
    "\n",
    "report_interval=1000\n",
    "\n",
    "score_to_solve = 195\n",
    "\n",
    "hidden_layer_size=64\n",
    "\n",
    "replay_memory_size=50000\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "update_target_frequency = 100\n",
    "\n",
    "clip_error=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Breakout-ramDeterministic-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.wrappers.Monitor(env, '../mp4/sandbox10',video_callable=lambda episode_id: True,force=True)\n",
    "#env = gym.wrappers.Monitor(env, '../mp4/breakout_DQN',video_callable=lambda episode_id: episode_id%100==0,force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs=env.observation_space.shape[0]\n",
    "number_of_outputs=env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_epsilon(steps_done):\n",
    "    epsilon = egreedy_final + (egreedy - egreedy_final) * \\\n",
    "              math.exp(-1. * steps_done / egreedy_decay )\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgt=torch.ones(replay_memory_size,dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.67 ms, sys: 0 ns, total: 3.67 ms\n",
      "Wall time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idx=torch.multinomial(wgt,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15018,  2728, 32530, 45059, 46524,  8180, 22552, 35787, 23232, 43800,\n",
       "        24464, 35876, 28608, 21180, 11842, 19710, 22402,  5147, 11506, 31323,\n",
       "        36580, 25896,  7959,  7764, 33009, 26003, 30352,  9672, 22488, 19258,\n",
       "        14059,  5543], device='cuda:4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay():\n",
    "    def __init__(self, capacity, state_size, state_dtype, action_dtype):\n",
    "        self.capacity=capacity\n",
    "        self.memory_state=torch.zeros([capacity, state_size],dtype=state_dtype).to(device)\n",
    "        self.memory_new_state=torch.zeros([capacity, state_size],dtype=state_dtype).to(device)\n",
    "        self.memory_action=torch.zeros([capacity, 1],dtype=action_dtype).to(device)\n",
    "        self.memory_reward=torch.zeros([capacity],dtype=torch.float32).to(device)\n",
    "        self.memory_done=torch.zeros([capacity],dtype=torch.long).to(device)\n",
    "        \n",
    "        self.filled_to=0\n",
    "        self.position=0\n",
    "        \n",
    "        self.state_dtype=state_dtype\n",
    "        self.action_dtype=action_dtype\n",
    "        \n",
    "        #this is a dummy equal weights vector to do random samples\n",
    "        self.wgt=torch.ones(capacity,dtype=torch.float32).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def push(self, state,\n",
    "             action, new_state,\n",
    "             reward, done):\n",
    "        \n",
    "            self.memory_state[self.position,:]=torch.tensor(state,dtype=self.state_dtype)\n",
    "            self.memory_new_state[self.position,:]=torch.tensor(new_state,dtype=self.state_dtype)\n",
    "            self.memory_action[self.position,0]=action\n",
    "            self.memory_reward[self.position]=reward\n",
    "            self.memory_done[self.position]=done\n",
    "            \n",
    "              \n",
    "            self.position=(self.position+1)%self.capacity\n",
    "            self.filled_to=min(self.capacity,self.filled_to+1)\n",
    "        \n",
    "    \n",
    "    def sample(self,batch_size):\n",
    "        \n",
    "        idx=torch.multinomial(self.wgt,batch_size)\n",
    "        #torch.randint(0,self.filled_to,(batch_size,),dtype=torch.long,device=device)\n",
    "        return (self.memory_state[idx],\n",
    "                self.memory_action[idx],\n",
    "                self.memory_new_state[idx],\n",
    "                self.memory_reward[idx],\n",
    "                self.memory_done[idx])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.filled_to\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(number_of_inputs,hidden_layer_size)\n",
    "        self.linear2 = nn.Linear(hidden_layer_size,number_of_outputs)\n",
    "        \n",
    "        self.activation=nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output1 = self.linear1(x)\n",
    "        output1 = self.activation(output1)\n",
    "        output2 = self.linear2(output1)\n",
    "        \n",
    "        return output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet_Agent():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.nn = NeuralNetwork().to(device)\n",
    "        self.target_nn = NeuralNetwork().to(device)\n",
    "        for p in self.nn.parameters():\n",
    "            print(p)\n",
    "        \n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(), lr=learning_rate)\n",
    "        \n",
    "        self.update_target_counter = 0\n",
    "        \n",
    "    def select_action(self,state,epsilon):\n",
    "        action=env.action_space.sample()\n",
    "        return action\n",
    "        \n",
    "        random_for_egreedy=torch.rand(1).item()\n",
    "        \n",
    "        if random_for_egreedy>epsilon:\n",
    "            self.nn.eval()\n",
    "            with torch.no_grad():\n",
    "                state=torch.Tensor(state).to(device)\n",
    "                predicted_value_from_nn=self.nn(state)\n",
    "                action=torch.argmax(predicted_value_from_nn).item()\n",
    "        else:\n",
    "            action=env.action_space.sample()\n",
    "        \n",
    "                \n",
    "        return action\n",
    "    \n",
    "    def optimize(self):\n",
    "        \n",
    "        if len(memory)<batch_size:\n",
    "            return\n",
    "        \n",
    "        state, action, new_state, reward, done = memory.sample(batch_size)\n",
    "        \n",
    "        #state=torch.Tensor(state).to(device)\n",
    "        #state.requires_grad_(False)\n",
    "        #new_state=torch.Tensor(new_state).to(device)\n",
    "        #new_state.requires_grad_(False)\n",
    "        #reward=torch.Tensor(reward).to(device)\n",
    "        #reward.requires_grad_(False)\n",
    "        #the view call below is to transform into column vector\n",
    "        #so that it can be used in the gather call\n",
    "        #i.e. we will use it to pick out from the computed value\n",
    "        #tensor only values indexed by selected action\n",
    "        #action=(torch.Tensor(action).view(-1,1).long()).to(device)\n",
    "        #action.requires_grad_(False)\n",
    "        #print('action: ')\n",
    "        #print(action)\n",
    "        #print('contiguous?', action.is_contiguous())\n",
    "        #done=torch.Tensor(done).to(device)\n",
    "        \n",
    "        #print('shape of: state, new state, reward, action, done:')\n",
    "        #print(state.shape)\n",
    "        #print(new_state.shape)\n",
    "        #print(reward.shape)\n",
    "        #print(action.shape)\n",
    "        #print(done.shape)\n",
    "        \n",
    "        \n",
    "        #self.nn.eval()\n",
    "        self.target_nn.eval()\n",
    "        with torch.set_grad_enabled(False):    \n",
    "            new_state_values=self.target_nn(new_state).detach()\n",
    "            #print('shape of: new_state_values')\n",
    "            #print(new_state_values.shape)\n",
    "        \n",
    "            max_new_state_values=torch.max(new_state_values,dim=1)[0]\n",
    "            #print('shape of: max_new_state_values')\n",
    "            #print(max_new_state_values.shape)\n",
    "            target_value=(reward + (1-done)*gamma*max_new_state_values).view(-1,1)\n",
    "        \n",
    "            #print('shape of: target_value')\n",
    "            #print(target_value.shape)\n",
    "            \n",
    "        self.nn.train()\n",
    "        \n",
    "        #this will select only the values of the desired actions\n",
    "        predicted_value=torch.gather(self.nn(state),1,action)\n",
    "        #print('shape of: predicted_value')\n",
    "        #print(predicted_value.shape)\n",
    "        \n",
    "        \n",
    "        loss=self.loss_function(predicted_value,target_value)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        if clip_error:\n",
    "            for param in self.nn.parameters():\n",
    "                param.grad.clamp_(-1.0,1.0)\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if self.update_target_counter % update_target_frequency == 0:\n",
    "            #print(\"***********************\")\n",
    "            #print(\"UPDATING TARGET NETWORK\")\n",
    "            #print(\"update counter: {}\".format(self.update_target_counter))\n",
    "            #print(\"***********************\")\n",
    "            self.target_nn.load_state_dict(self.nn.state_dict())\n",
    "        \n",
    "        self.update_target_counter+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ExperienceReplay(replay_memory_size,\n",
    "                        env.observation_space.shape[0],\n",
    "                        torch.float32,\n",
    "                        torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0271,  0.0017, -0.0872,  ..., -0.0401, -0.0049, -0.0484],\n",
      "        [-0.0659,  0.0376,  0.0601,  ..., -0.0319, -0.0242, -0.0454],\n",
      "        [ 0.0041, -0.0184, -0.0325,  ...,  0.0510,  0.0219, -0.0124],\n",
      "        ...,\n",
      "        [ 0.0520, -0.0518, -0.0135,  ..., -0.0455, -0.0001,  0.0712],\n",
      "        [ 0.0429, -0.0015, -0.0524,  ...,  0.0127, -0.0466,  0.0117],\n",
      "        [ 0.0472,  0.0472, -0.0585,  ..., -0.0517,  0.0163, -0.0068]],\n",
      "       device='cuda:4', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-7.9178e-02, -8.2425e-02, -8.0187e-02,  6.5750e-02,  6.6049e-02,\n",
      "         1.6305e-02, -2.1114e-02, -3.7307e-02, -7.7928e-02,  2.4560e-02,\n",
      "        -8.6045e-02, -3.1636e-02,  6.6272e-03,  6.8194e-03, -4.5986e-02,\n",
      "         8.7397e-02,  8.4012e-02,  3.0084e-02,  7.4705e-02,  1.4692e-03,\n",
      "        -3.3653e-02, -1.3146e-02,  7.8831e-02,  6.0976e-02,  7.1231e-02,\n",
      "        -4.0617e-02,  2.9206e-02, -7.2433e-02,  3.4168e-02,  7.7068e-02,\n",
      "         5.5882e-02, -3.9530e-02, -6.2091e-02,  1.4303e-02, -4.2847e-02,\n",
      "        -2.6150e-02,  6.3118e-03,  5.8741e-02,  5.2773e-02, -4.4448e-02,\n",
      "        -3.1767e-02, -8.4227e-02,  4.9262e-02,  6.6913e-02,  4.8810e-02,\n",
      "         4.5966e-02,  6.1671e-02,  3.1153e-02,  6.2704e-02,  8.5064e-02,\n",
      "         6.2652e-02, -2.4400e-02,  7.7789e-02,  2.0803e-02, -5.7370e-02,\n",
      "        -3.4869e-02, -5.5574e-05, -3.1802e-02, -3.6399e-02,  2.0454e-02,\n",
      "        -2.9596e-03, -3.0428e-02, -8.0771e-02, -7.2107e-02], device='cuda:4',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0721,  0.1110,  0.0716,  0.0571, -0.1227,  0.0917,  0.0491,  0.0171,\n",
      "         -0.1213, -0.0998, -0.1153, -0.0714, -0.0984, -0.0550,  0.0722, -0.0974,\n",
      "          0.0219,  0.0730,  0.0550, -0.0085,  0.0242,  0.0335, -0.1019,  0.0111,\n",
      "          0.1188,  0.1212,  0.0866, -0.1192,  0.0529,  0.0114,  0.0039, -0.1084,\n",
      "          0.0823,  0.0197, -0.0827,  0.1224, -0.0105,  0.0953, -0.0332, -0.1125,\n",
      "          0.0111, -0.0644,  0.0257, -0.0563, -0.1014,  0.0868,  0.1237, -0.0339,\n",
      "          0.0807, -0.0070,  0.0238,  0.0118,  0.0907, -0.0170, -0.0444,  0.0113,\n",
      "          0.0565, -0.0216,  0.0274,  0.0335, -0.1180,  0.0444, -0.0062, -0.0191],\n",
      "        [-0.0799,  0.0149, -0.0325,  0.0628,  0.0413, -0.0006,  0.0126,  0.0090,\n",
      "         -0.0088,  0.1088, -0.0792, -0.0504, -0.0262,  0.0941, -0.0231, -0.0190,\n",
      "          0.0938,  0.0477,  0.1184,  0.0886, -0.0068, -0.0873,  0.0832,  0.0662,\n",
      "         -0.0593,  0.0331, -0.0838,  0.0199,  0.0299, -0.1118,  0.0412,  0.1047,\n",
      "          0.0139,  0.0249, -0.0273,  0.0540,  0.0627, -0.1122,  0.0941,  0.1036,\n",
      "         -0.0030, -0.0777, -0.0759,  0.1100,  0.0918,  0.0644, -0.0535, -0.0620,\n",
      "          0.0950,  0.1068, -0.0082, -0.0470,  0.0216,  0.1134,  0.0901, -0.0499,\n",
      "          0.1063,  0.1213,  0.0888,  0.0323,  0.0044,  0.0878, -0.0849, -0.1009],\n",
      "        [ 0.0849,  0.0755,  0.0966,  0.0192, -0.0141, -0.0611, -0.0225,  0.1198,\n",
      "         -0.0225, -0.1065,  0.1197,  0.0607,  0.0793,  0.0480, -0.0254, -0.0457,\n",
      "          0.0959,  0.0815,  0.0369,  0.1074, -0.1023, -0.0036, -0.0072,  0.1168,\n",
      "         -0.0304, -0.1077, -0.0634,  0.0214,  0.0562,  0.0391,  0.0709,  0.0210,\n",
      "          0.0191,  0.0271, -0.0238,  0.1052,  0.0926,  0.0090, -0.0088,  0.0571,\n",
      "          0.0978,  0.0084,  0.0269,  0.0026, -0.1215, -0.0884,  0.0182, -0.1122,\n",
      "         -0.0547,  0.0455, -0.0223,  0.0759,  0.0522,  0.0455, -0.0282, -0.0359,\n",
      "          0.0876,  0.1199,  0.0903, -0.1054,  0.0437,  0.0386, -0.0310, -0.1159],\n",
      "        [-0.1244, -0.0293, -0.0473,  0.1067, -0.0746, -0.1042, -0.0265, -0.0344,\n",
      "         -0.0583,  0.0384, -0.0729, -0.1074,  0.1245,  0.0690,  0.0646, -0.0638,\n",
      "          0.0779, -0.0796,  0.0783, -0.0803,  0.0025,  0.0550, -0.1236, -0.0801,\n",
      "         -0.0948,  0.0330, -0.1126, -0.0422, -0.1211, -0.0923,  0.1178,  0.0808,\n",
      "         -0.1121, -0.0100,  0.1174,  0.1043,  0.0493, -0.1152, -0.0613,  0.0600,\n",
      "         -0.0543, -0.0244, -0.0591, -0.0623, -0.0034, -0.0721,  0.0156, -0.0915,\n",
      "         -0.0063,  0.0501, -0.0888, -0.0183,  0.1103, -0.0506,  0.0892, -0.0944,\n",
      "          0.0424,  0.0242,  0.0603,  0.1108, -0.0592, -0.0191, -0.0322,  0.0386]],\n",
      "       device='cuda:4', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1029,  0.0747, -0.0852,  0.0014], device='cuda:4',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "qnet_agent=QNet_Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value=23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_agent():\n",
    "    steps_total=np.full([num_episodes],-999,dtype=np.int32)\n",
    "    reward_total=np.full([num_episodes],-999,dtype=np.int32)\n",
    "\n",
    "    frames_total=0\n",
    "\n",
    "    solved_after = 0\n",
    "    solved = False\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "    \n",
    "        state = env.reset()\n",
    "        #for step in range(100):\n",
    "        step=0\n",
    "        reward_total[i_episode]=0\n",
    "    \n",
    "        while True:\n",
    "        \n",
    "            step+=1\n",
    "            frames_total += 1\n",
    "\n",
    "            epsilon=calculate_epsilon(frames_total)\n",
    "\n",
    "            #action=env.action_space.sample()\n",
    "            action=qnet_agent.select_action(state,epsilon)\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            memory.push(state, action, new_state,\n",
    "                        reward, done)\n",
    "\n",
    "            reward_total[i_episode]+=reward\n",
    "\n",
    "            qnet_agent.optimize()\n",
    "\n",
    "            state=new_state\n",
    "        \n",
    "        \n",
    "            if done:\n",
    "                steps_total[i_episode]=step\n",
    "\n",
    "                if i_episode>100:\n",
    "                    mean_reward_100 = np.sum(reward_total[i_episode-100:i_episode])/100\n",
    "\n",
    "                    if (mean_reward_100 > score_to_solve and solved == False):\n",
    "                        print(\"SOLVED! After %i episodes \" % i_episode)\n",
    "                        solved_after = i_episode\n",
    "                        solved = True\n",
    "\n",
    "                if (i_episode % report_interval == 0 and i_episode>1):\n",
    "                    print(\"**** Episode  {} **** \".format(i_episode))\n",
    "                    recent_avg_reward=np.average(reward_total[i_episode-report_interval:i_episode])\n",
    "                    print(\"Recent average reward: {}\".format(recent_avg_reward))\n",
    "                    if i_episode>100:\n",
    "                        print(\"Reward over last 100: {}\".format(mean_reward_100))\n",
    "                    full_avg_so_far=np.average(reward_total[:i_episode])\n",
    "                    print(\"Average over all episodes so far: {}\".format(full_avg_so_far))\n",
    "                    print(\"epsilon: {}\".format(epsilon))\n",
    "\n",
    "                    #print(\"Episode {} finished after: {}\".format(i_episode,step))\n",
    "                break\n",
    "\n",
    "    if solved:\n",
    "        print(\"Solved after %i episodes\" % solved_after)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### %lprun -f train_agent train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Episode  1000 **** \n",
      "Recent average reward: 1.121\n",
      "Reward over last 100: 1.06\n",
      "Average over all episodes so far: 1.121\n",
      "epsilon: 0.01\n",
      "**** Episode  2000 **** \n",
      "Recent average reward: 1.092\n",
      "Reward over last 100: 1.21\n",
      "Average over all episodes so far: 1.1065\n",
      "epsilon: 0.01\n",
      "**** Episode  3000 **** \n",
      "Recent average reward: 1.029\n",
      "Reward over last 100: 1.05\n",
      "Average over all episodes so far: 1.0806666666666667\n",
      "epsilon: 0.01\n",
      "**** Episode  4000 **** \n",
      "Recent average reward: 1.102\n",
      "Reward over last 100: 1.06\n",
      "Average over all episodes so far: 1.086\n",
      "epsilon: 0.01\n"
     ]
    }
   ],
   "source": [
    "%lprun -f ExperienceReplay.sample -f ExperienceReplay.push -f QNet_Agent.optimize -f train_agent train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=[12,5])\n",
    "plt.title(\"Score at end of episode\")\n",
    "plt.plot(reward_total[:frames_total])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of steps: 176.509\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of steps: {}\". format(np.average(steps_total[:num_episodes])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of steps: 176.509\n",
      "Average reward in last 100 episodes: 1.04\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of steps: {}\". format(np.average(steps_total)))\n",
    "print(\"Average reward in last 100 episodes: {}\". format(np.average(reward_total[num_episodes-100:num_episodes])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882545"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for just running the env; no mp4; 50000 episodes:  \n",
    "CPU times: user 1h 28min 6s, sys: 19.4 s, total: 1h 28min 26s\n",
    "Wall time: 1h 28min 8s  \n",
    "Average number of steps: 177.34648\n",
    "Average reward in last 100 episodes: 1.13\n",
    "\n",
    "for also storing action 5000 episodes\n",
    "CPU times: user 8min 56s, sys: 3.69 s, total: 9min\n",
    "Wall time: 8min 58s\n",
    "- this is adding oly 10s over 5k episodes dedicated to filling the memory\n",
    "\n",
    "for also selecting an action using nn (starting eps=0.1) (5k episodes): \n",
    "CPU times: user 10min 19s, sys: 3.1 s, total: 10min 22s\n",
    "Wall time: 10min 21s\n",
    "\n",
    "for also sampling the memory:\n",
    "CPU times: user 10min 51s, sys: 1.97 s, total: 10min 53s\n",
    "Wall time: 10min 52s\n",
    "\n",
    "for full thing (5000 episodes)\n",
    "CPU times: user 1h 19min 2s, sys: 20min 18s, total: 1h 39min 20s\n",
    "Wall time: 1h 39min 12s\n",
    "\n",
    "\n",
    "\n",
    "5000 episodes full thing line profiling:\n",
    "\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 4073.5 s\n",
    "File: <ipython-input-15-0f42c0df46c8>\n",
    "Function: optimize at line 30\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    30                                               def optimize(self):\n",
    "    31                                                   \n",
    "    32    887138    3359323.0      3.8      0.1          if len(memory)<batch_size:\n",
    "    33                                                       return\n",
    "    34                                                   \n",
    "    35    887138  207028244.0    233.4      5.1          state, action, new_state, reward, done = memory.sample(batch_size)\n",
    "    36                                                   \n",
    "    37    887138  716564489.0    807.7     17.6          state=torch.Tensor(state).to(device)\n",
    "    38    887138  682248656.0    769.0     16.7          new_state=torch.Tensor(new_state).to(device)\n",
    "    39    887138   29214742.0     32.9      0.7          reward=torch.Tensor(reward).to(device)\n",
    "    40                                                   \n",
    "    41                                                   #the view call below is to transform into column vector\n",
    "    42                                                   #so that it can be used in the gather call\n",
    "    43                                                   #i.e. we will use it to pick out from the computed value\n",
    "                                                                                    \n",
    "    44                                                   #tensor only values indexed by selected action\n",
    "    45    887138   52334732.0     59.0      1.3          action=(torch.Tensor(action).view(-1,1).long()).to(device)\n",
    "    46                                                   #print('action: ')\n",
    "    47                                                   #print(action)\n",
    "    48                                                   #print('contiguous?', action.is_contiguous())\n",
    "    49    887138   27262792.0     30.7      0.7          done=torch.Tensor(done).to(device)\n",
    "    50                                                   \n",
    "    51                                                   #print('shape of: state, new state, reward, action, done:')\n",
    "    52                                                   #print(state.shape)\n",
    "    53                                                   #print(new_state.shape)\n",
    "    54                                                   #print(reward.shape)\n",
    "    55                                                   #print(action.shape)\n",
    "    56                                                   #print(done.shape)\n",
    "    57                                                   \n",
    "    58                                                   \n",
    "    59    887138   68419159.0     77.1      1.7          self.nn.eval()\n",
    "    60    887138   48190975.0     54.3      1.2          self.target_nn.eval()\n",
    "    61                                                       \n",
    "    62    887138  218498245.0    246.3      5.4          new_state_values=self.target_nn(new_state).detach()\n",
    "    63                                                   #print('shape of: new_state_values')\n",
    "    64                                                   #print(new_state_values.shape)\n",
    "    65                                                   \n",
    "    66    887138   31577595.0     35.6      0.8          max_new_state_values=torch.max(new_state_values,dim=1)[0]\n",
    "    67                                                   #print('shape of: max_new_state_values')\n",
    "    68                                                   #print(max_new_state_values.shape)\n",
    "    69    887138  115804397.0    130.5      2.8          target_value=(reward + (1-done)*gamma*max_new_state_values).view(-1,1)\n",
    "    70                                                   \n",
    "    71                                                   #print('shape of: target_value')\n",
    "    72                                                   #print(target_value.shape)\n",
    "    73    887138   58834761.0     66.3      1.4          self.nn.train()\n",
    "    74                                                   \n",
    "    75                                                   #this will select only the values of the desired actions\n",
    "    76    887138  205661260.0    231.8      5.0          predicted_value=torch.gather(self.nn(state),1,action)\n",
    "    77                                                   #print('shape of: predicted_value')\n",
    "    78                                                   #print(predicted_value.shape)\n",
    "    79                                                   \n",
    "    80                                                   \n",
    "    81    887138   73987605.0     83.4      1.8          loss=self.loss_function(predicted_value,target_value)\n",
    "    82    887138   58915118.0     66.4      1.4          self.optimizer.zero_grad()\n",
    "    83    887138  772975201.0    871.3     19.0          loss.backward()\n",
    "    84                                                   \n",
    "    85    887138    2187213.0      2.5      0.1          if clip_error:\n",
    "    86                                                       for param in self.nn.parameters():\n",
    "    87                                                           param.grad.clamp_(-1.0,1.0)\n",
    "    88                                                   \n",
    "    89    887138  693066454.0    781.2     17.0          self.optimizer.step()\n",
    "    90                                                   \n",
    "    91    887138    2710617.0      3.1      0.1          if self.update_target_counter % update_target_frequency == 0:\n",
    "    92                                                       #print(\"***********************\")\n",
    "    93                                                       #print(\"UPDATING TARGET NETWORK\")\n",
    "    94                                                       #print(\"update counter: {}\".format(self.update_target_counter))\n",
    "    95                                                       #print(\"***********************\")\n",
    "    96      8871    2748086.0    309.8      0.1              self.target_nn.load_state_dict(self.nn.state_dict())\n",
    "    97                                                   \n",
    "    98    887138    1911335.0      2.2      0.0          self.update_target_counter+=1\n",
    "\n",
    "Total time: 5181.55 s\n",
    "File: <ipython-input-23-8f49ffd4dfdc>\n",
    "    \n",
    "    \n",
    "    \n",
    "# randint sampling:\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 290.136 s\n",
    "File: <ipython-input-17-576c7d09f2f1>\n",
    "Function: push at line 21\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    21                                               def push(self, state,\n",
    "    22                                                        action, new_state,\n",
    "    23                                                        reward, done):\n",
    "    24                                                   \n",
    "    25    889834  100576649.0    113.0     34.7              self.memory_state[self.position,:]=torch.tensor(state,dtype=self.state_dtype)\n",
    "    26    889834   49530240.0     55.7     17.1              self.memory_new_state[self.position,:]=torch.tensor(new_state,dtype=self.state_dtype)\n",
    "    27    889834   59512593.0     66.9     20.5              self.memory_action[self.position,0]=action\n",
    "    28    889834   39710386.0     44.6     13.7              self.memory_reward[self.position]=reward\n",
    "    29    889834   34742775.0     39.0     12.0              self.memory_done[self.position]=done\n",
    "    30                                                       \n",
    "    31                                                         \n",
    "    32    889834    2464796.0      2.8      0.8              self.position=(self.position+1)%self.capacity\n",
    "    33    889834    3598973.0      4.0      1.2              self.filled_to=min(self.capacity,self.filled_to+1)\n",
    "\n",
    "Total time: 168.544 s\n",
    "File: <ipython-input-17-576c7d09f2f1>\n",
    "Function: sample at line 36\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    36                                               def sample(self,batch_size):\n",
    "    37                                                   \n",
    "    38                                                   #idx=torch.multinomial(self.wgt,batch_size)\n",
    "    39    889803   31660965.0     35.6     18.8          torch.randint(0,self.filled_to,(batch_size,),dtype=torch.long,device=device)\n",
    "    40    889803   42294848.0     47.5     25.1          return (self.memory_state[idx],\n",
    "    41    889803   25687324.0     28.9     15.2                  self.memory_action[idx],\n",
    "    42    889803   23916755.0     26.9     14.2                  self.memory_new_state[idx],\n",
    "    43    889803   23182104.0     26.1     13.8                  self.memory_reward[idx],\n",
    "    44    889803   21801538.0     24.5     12.9                  self.memory_done[idx])\n",
    "\n",
    "Total time: 2800.33 s\n",
    "File: <ipython-input-19-a79d60f1377a>\n",
    "Function: optimize at line 32\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    32                                               def optimize(self):\n",
    "    33                                                   \n",
    "    34    889834    4353881.0      4.9      0.2          if len(memory)<batch_size:\n",
    "    35        31         37.0      1.2      0.0              return\n",
    "    36                                                   \n",
    "    37    889803  177345080.0    199.3      6.3          state, action, new_state, reward, done = memory.sample(batch_size)\n",
    "    38                                                   \n",
    "    39                                                   #state=torch.Tensor(state).to(device)\n",
    "    40                                                   #state.requires_grad_(False)\n",
    "    41                                                   #new_state=torch.Tensor(new_state).to(device)\n",
    "    42                                                   #new_state.requires_grad_(False)\n",
    "    43                                                   #reward=torch.Tensor(reward).to(device)\n",
    "    44                                                   #reward.requires_grad_(False)\n",
    "    45                                                   #the view call below is to transform into column vector\n",
    "    46                                                   #so that it can be used in the gather call\n",
    "    47                                                   #i.e. we will use it to pick out from the computed value\n",
    "    48                                                   #tensor only values indexed by selected action\n",
    "    49                                                   #action=(torch.Tensor(action).view(-1,1).long()).to(device)\n",
    "    50                                                   #action.requires_grad_(False)\n",
    "    51                                                   #print('action: ')\n",
    "    52                                                   #print(action)\n",
    "    53                                                   #print('contiguous?', action.is_contiguous())\n",
    "    54                                                   #done=torch.Tensor(done).to(device)\n",
    "    55                                                   \n",
    "    56                                                   #print('shape of: state, new state, reward, action, done:')\n",
    "    57                                                   #print(state.shape)\n",
    "    58                                                   #print(new_state.shape)\n",
    "    59                                                   #print(reward.shape)\n",
    "    60                                                   #print(action.shape)\n",
    "    61                                                   #print(done.shape)\n",
    "    62                                                   \n",
    "    63                                                   \n",
    "    64                                                   #self.nn.eval()\n",
    "    65    889803   74046917.0     83.2      2.6          self.target_nn.eval()\n",
    "    66    889803    7552511.0      8.5      0.3          with torch.set_grad_enabled(False):    \n",
    "    67    889803  207276703.0    232.9      7.4              new_state_values=self.target_nn(new_state).detach()\n",
    "    68                                                       #print('shape of: new_state_values')\n",
    "    69                                                       #print(new_state_values.shape)\n",
    "    70                                                   \n",
    "    71    889803   34352347.0     38.6      1.2              max_new_state_values=torch.max(new_state_values,dim=1)[0]\n",
    "    72                                                       #print('shape of: max_new_state_values')\n",
    "    73                                                       #print(max_new_state_values.shape)\n",
    "    74    889803  133380589.0    149.9      4.8              target_value=(reward + (1-done)*gamma*max_new_state_values).view(-1,1)\n",
    "    75                                                   \n",
    "    76                                                       #print('shape of: target_value')\n",
    "    77                                                       #print(target_value.shape)\n",
    "    78                                                       \n",
    "    79    889803   62277301.0     70.0      2.2          self.nn.train()\n",
    "    80                                                   \n",
    "    81                                                   #this will select only the values of the desired actions\n",
    "    82    889803  230407230.0    258.9      8.2          predicted_value=torch.gather(self.nn(state),1,action)\n",
    "    83                                                   #print('shape of: predicted_value')\n",
    "    84                                                   #print(predicted_value.shape)\n",
    "    85                                                   \n",
    "    86                                                   \n",
    "    87    889803   83103230.0     93.4      3.0          loss=self.loss_function(predicted_value,target_value)\n",
    "    88    889803   64160181.0     72.1      2.3          self.optimizer.zero_grad()\n",
    "    89    889803  897196716.0   1008.3     32.0          loss.backward()\n",
    "    90                                                   \n",
    "    91    889803    4140335.0      4.7      0.1          if clip_error:\n",
    "    92                                                       for param in self.nn.parameters():\n",
    "    93                                                           param.grad.clamp_(-1.0,1.0)\n",
    "    94                                                   \n",
    "    95    889803  812652828.0    913.3     29.0          self.optimizer.step()\n",
    "    96                                                   \n",
    "    97    889803    3199095.0      3.6      0.1          if self.update_target_counter % update_target_frequency == 0:\n",
    "    98                                                       #print(\"***********************\")\n",
    "    99                                                       #print(\"UPDATING TARGET NETWORK\")\n",
    "   100                                                       #print(\"update counter: {}\".format(self.update_target_counter))\n",
    "   101                                                       #print(\"***********************\")\n",
    "   102      8899    2806076.0    315.3      0.1              self.target_nn.load_state_dict(self.nn.state_dict())\n",
    "   103                                                   \n",
    "   104    889803    2075509.0      2.3      0.1          self.update_target_counter+=1\n",
    "\n",
    "Total time: 4264.18 s\n",
    "File: <ipython-input-26-8f49ffd4dfdc>\n",
    "Function: train_agent at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def train_agent():\n",
    "     2         1        265.0    265.0      0.0      steps_total=np.full([num_episodes],-999,dtype=np.int32)\n",
    "     3         1         45.0     45.0      0.0      reward_total=np.full([num_episodes],-999,dtype=np.int32)\n",
    "     4                                           \n",
    "     5         1          2.0      2.0      0.0      frames_total=0\n",
    "     6                                           \n",
    "     7         1          2.0      2.0      0.0      solved_after = 0\n",
    "     8         1          3.0      3.0      0.0      solved = False\n",
    "     9                                           \n",
    "    10                                           \n",
    "    11         1          6.0      6.0      0.0      start_time = time.time()\n",
    "    12                                           \n",
    "    13      5001       7202.0      1.4      0.0      for i_episode in range(num_episodes):\n",
    "    14                                               \n",
    "    15      5000   75816573.0  15163.3      1.8          state = env.reset()\n",
    "    16                                                   #for step in range(100):\n",
    "    17      5000       8991.0      1.8      0.0          step=0\n",
    "    18      5000      11946.0      2.4      0.0          reward_total[i_episode]=0\n",
    "    19                                               \n",
    "    20      5000       6022.0      1.2      0.0          while True:\n",
    "    21                                                   \n",
    "    22    889834    1192687.0      1.3      0.0              step+=1\n",
    "    23    889834    1228575.0      1.4      0.0              frames_total += 1\n",
    "    24                                           \n",
    "    25    889834    6235778.0      7.0      0.1              epsilon=calculate_epsilon(frames_total)\n",
    "    26                                           \n",
    "    27                                                       #action=env.action_space.sample()\n",
    "    28    889834   59035586.0     66.3      1.4              action=qnet_agent.select_action(state,epsilon)\n",
    "    29                                           \n",
    "    30    889834  935042763.0   1050.8     21.9              new_state, reward, done, info = env.step(action)\n",
    "    31    889834    2106425.0      2.4      0.0              memory.push(state, action, new_state,\n",
    "    32    889834  300053356.0    337.2      7.0                          reward, done)\n",
    "    33                                           \n",
    "    34    889834   23111585.0     26.0      0.5              reward_total[i_episode]+=reward\n",
    "    35                                           \n",
    "    36    889834 2855919520.0   3209.5     67.0              qnet_agent.optimize()\n",
    "    37                                           \n",
    "    38    889834    2925834.0      3.3      0.1              state=new_state\n",
    "    39                                                   \n",
    "    40                                                   \n",
    "    41    889834    1153529.0      1.3      0.0              if done:\n",
    "    42      5000      17092.0      3.4      0.0                  steps_total[i_episode]=step\n",
    "    43                                           \n",
    "    44      5000       7474.0      1.5      0.0                  if i_episode>100:\n",
    "    45      4899     254565.0     52.0      0.0                      mean_reward_100 = np.sum(reward_total[i_episode-100:i_episode])/100\n",
    "    46                                           \n",
    "    47      4899      17653.0      3.6      0.0                      if (mean_reward_100 > score_to_solve and solved == False):\n",
    "    48                                                                   print(\"SOLVED! After %i episodes \" % i_episode)\n",
    "    49                                                                   solved_after = i_episode\n",
    "    50                                                                   solved = True\n",
    "    51                                           \n",
    "    52      5000       8114.0      1.6      0.0                  if (i_episode % report_interval == 0 and i_episode>1):\n",
    "    53         4       2294.0    573.5      0.0                      print(\"**** Episode  {} **** \".format(i_episode))\n",
    "    54         4       3260.0    815.0      0.0                      recent_avg_reward=np.average(reward_total[i_episode-report_interval:i_episode])\n",
    "    55         4        373.0     93.2      0.0                      print(\"Recent average reward: {}\".format(recent_avg_reward))\n",
    "    56         4          8.0      2.0      0.0                      if i_episode>100:\n",
    "    57         4        224.0     56.0      0.0                          print(\"Reward over last 100: {}\".format(mean_reward_100))\n",
    "    58         4        297.0     74.2      0.0                      full_avg_so_far=np.average(reward_total[:i_episode])\n",
    "    59         4        220.0     55.0      0.0                      print(\"Average over all episodes so far: {}\".format(full_avg_so_far))\n",
    "    60         4        200.0     50.0      0.0                      print(\"epsilon: {}\".format(epsilon))\n",
    "    61                                           \n",
    "    62                                                               #print(\"Episode {} finished after: {}\".format(i_episode,step))\n",
    "    63      5000       6665.0      1.3      0.0                  break\n",
    "    64                                           \n",
    "    65         1          1.0      1.0      0.0      if solved:\n",
    "    66                                                   print(\"Solved after %i episodes\" % solved_after)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# multinomial sampling (no max (so buggy)):\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 34357.5 s\n",
    "File: <ipython-input-17-f863b8eb5576>\n",
    "Function: push at line 21\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    21                                               def push(self, state,\n",
    "    22                                                        action, new_state,\n",
    "    23                                                        reward, done):\n",
    "    24                                                   \n",
    "    25    887359 34169597747.0  38507.1     99.5              self.memory_state[self.position,:]=torch.tensor(state,dtype=self.state_dtype)\n",
    "    26    887359   55937921.0     63.0      0.2              self.memory_new_state[self.position,:]=torch.tensor(new_state,dtype=self.state_dtype)\n",
    "    27    887359   56721573.0     63.9      0.2              self.memory_action[self.position,0]=action\n",
    "    28    887359   36595475.0     41.2      0.1              self.memory_reward[self.position]=reward\n",
    "    29    887359   32991397.0     37.2      0.1              self.memory_done[self.position]=done\n",
    "    30                                                       \n",
    "    31                                                         \n",
    "    32    887359    2572369.0      2.9      0.0              self.position=(self.position+1)%self.capacity\n",
    "    33    887359    3071084.0      3.5      0.0              self.filled_to=min(self.capacity,self.filled_to+1)\n",
    "\n",
    "Total time: 934.219 s\n",
    "File: <ipython-input-17-f863b8eb5576>\n",
    "Function: sample at line 36\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    36                                               def sample(self,batch_size):\n",
    "    37                                                   \n",
    "    38    887328  807357421.0    909.9     86.4          idx=torch.multinomial(self.wgt,batch_size)\n",
    "    39                                                   #torch.randint(0,self.filled_to,(batch_size,),dtype=torch.long,device=device)\n",
    "    40    887328   38666057.0     43.6      4.1          return (self.memory_state[idx],\n",
    "    41    887328   24283301.0     27.4      2.6                  self.memory_action[idx],\n",
    "    42    887328   21810904.0     24.6      2.3                  self.memory_new_state[idx],\n",
    "    43    887328   20950187.0     23.6      2.2                  self.memory_reward[idx],\n",
    "    44    887328   21151460.0     23.8      2.3                  self.memory_done[idx])\n",
    "\n",
    "Total time: 3696.76 s\n",
    "File: <ipython-input-19-a79d60f1377a>\n",
    "Function: optimize at line 32\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    32                                               def optimize(self):\n",
    "    33                                                   \n",
    "    34    887359    4060660.0      4.6      0.1          if len(memory)<batch_size:\n",
    "    35        31         38.0      1.2      0.0              return\n",
    "    36                                                   \n",
    "    37    887328  943524281.0   1063.3     25.5          state, action, new_state, reward, done = memory.sample(batch_size)\n",
    "    38                                                   \n",
    "    39                                                   #state=torch.Tensor(state).to(device)\n",
    "    40                                                   #state.requires_grad_(False)\n",
    "    41                                                   #new_state=torch.Tensor(new_state).to(device)\n",
    "    42                                                   #new_state.requires_grad_(False)\n",
    "    43                                                   #reward=torch.Tensor(reward).to(device)\n",
    "    44                                                   #reward.requires_grad_(False)\n",
    "    45                                                   #the view call below is to transform into column vector\n",
    "    46                                                   #so that it can be used in the gather call\n",
    "    47                                                   #i.e. we will use it to pick out from the computed value\n",
    "    48                                                   #tensor only values indexed by selected action\n",
    "    49                                                   #action=(torch.Tensor(action).view(-1,1).long()).to(device)\n",
    "    50                                                   #action.requires_grad_(False)\n",
    "    51                                                   #print('action: ')\n",
    "    52                                                   #print(action)\n",
    "    53                                                   #print('contiguous?', action.is_contiguous())\n",
    "    54                                                   #done=torch.Tensor(done).to(device)\n",
    "    55                                                   \n",
    "    56                                                   #print('shape of: state, new state, reward, action, done:')\n",
    "    57                                                   #print(state.shape)\n",
    "    58                                                   #print(new_state.shape)\n",
    "    59                                                   #print(reward.shape)\n",
    "    60                                                   #print(action.shape)\n",
    "    61                                                   #print(done.shape)\n",
    "    62                                                   \n",
    "    63                                                   \n",
    "    64                                                   #self.nn.eval()\n",
    "    65    887328   69361203.0     78.2      1.9          self.target_nn.eval()\n",
    "    66    887328    7032881.0      7.9      0.2          with torch.set_grad_enabled(False):    \n",
    "    67    887328  193245243.0    217.8      5.2              new_state_values=self.target_nn(new_state).detach()\n",
    "    68                                                       #print('shape of: new_state_values')\n",
    "    69                                                       #print(new_state_values.shape)\n",
    "    70                                                   \n",
    "    71    887328   31701066.0     35.7      0.9              max_new_state_values=torch.max(new_state_values,dim=1)[0]\n",
    "    72                                                       #print('shape of: max_new_state_values')\n",
    "    73                                                       #print(max_new_state_values.shape)\n",
    "    74    887328  126365153.0    142.4      3.4              target_value=(reward + (1-done)*gamma*max_new_state_values).view(-1,1)\n",
    "    75                                                   \n",
    "    76                                                       #print('shape of: target_value')\n",
    "    77                                                       #print(target_value.shape)\n",
    "    78                                                       \n",
    "    79    887328   56871773.0     64.1      1.5          self.nn.train()\n",
    "    80                                                   \n",
    "    81                                                   #this will select only the values of the desired actions\n",
    "    82    887328  218686302.0    246.5      5.9          predicted_value=torch.gather(self.nn(state),1,action)\n",
    "    83                                                   #print('shape of: predicted_value')\n",
    "    84                                                   #print(predicted_value.shape)\n",
    "    85                                                   \n",
    "    86                                                   \n",
    "    87    887328   78276841.0     88.2      2.1          loss=self.loss_function(predicted_value,target_value)\n",
    "    88    887328   60699406.0     68.4      1.6          self.optimizer.zero_grad()\n",
    "    89    887328 1053556559.0   1187.3     28.5          loss.backward()\n",
    "    90                                                   \n",
    "    91    887328    5040711.0      5.7      0.1          if clip_error:\n",
    "    92                                                       for param in self.nn.parameters():\n",
    "    93                                                           param.grad.clamp_(-1.0,1.0)\n",
    "    94                                                   \n",
    "    95    887328  840738764.0    947.5     22.7          self.optimizer.step()\n",
    "    96                                                   \n",
    "    97    887328    3024155.0      3.4      0.1          if self.update_target_counter % update_target_frequency == 0:\n",
    "    98                                                       #print(\"***********************\")\n",
    "    99                                                       #print(\"UPDATING TARGET NETWORK\")\n",
    "   100                                                       #print(\"update counter: {}\".format(self.update_target_counter))\n",
    "   101                                                       #print(\"***********************\")\n",
    "   102      8874    2691358.0    303.3      0.1              self.target_nn.load_state_dict(self.nn.state_dict())\n",
    "   103                                                   \n",
    "   104    887328    1880786.0      2.1      0.1          self.update_target_counter+=1\n",
    "\n",
    "Total time: 39111.1 s\n",
    "File: <ipython-input-26-8f49ffd4dfdc>\n",
    "Function: train_agent at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def train_agent():\n",
    "     2         1         90.0     90.0      0.0      steps_total=np.full([num_episodes],-999,dtype=np.int32)\n",
    "     3         1         30.0     30.0      0.0      reward_total=np.full([num_episodes],-999,dtype=np.int32)\n",
    "     4                                           \n",
    "     5         1          3.0      3.0      0.0      frames_total=0\n",
    "     6                                           \n",
    "     7         1          2.0      2.0      0.0      solved_after = 0\n",
    "     8         1          2.0      2.0      0.0      solved = False\n",
    "     9                                           \n",
    "    10                                           \n",
    "    11         1          3.0      3.0      0.0      start_time = time.time()\n",
    "    12                                           \n",
    "    13      5001       7728.0      1.5      0.0      for i_episode in range(num_episodes):\n",
    "    14                                               \n",
    "    15      5000   70174953.0  14035.0      0.2          state = env.reset()\n",
    "    16                                                   #for step in range(100):\n",
    "    17      5000       9194.0      1.8      0.0          step=0\n",
    "    18      5000      12349.0      2.5      0.0          reward_total[i_episode]=0\n",
    "    19                                               \n",
    "    20      5000       6021.0      1.2      0.0          while True:\n",
    "    21                                                   \n",
    "    22    887359    1117140.0      1.3      0.0              step+=1\n",
    "    23    887359    1136657.0      1.3      0.0              frames_total += 1\n",
    "    24                                           \n",
    "    25    887359    5759222.0      6.5      0.0              epsilon=calculate_epsilon(frames_total)\n",
    "    26                                           \n",
    "    27                                                       #action=env.action_space.sample()\n",
    "    28    887359   52579224.0     59.3      0.1              action=qnet_agent.select_action(state,epsilon)\n",
    "    29                                           \n",
    "    30    887359  826258821.0    931.1      2.1              new_state, reward, done, info = env.step(action)\n",
    "    31    887359    1912579.0      2.2      0.0              memory.push(state, action, new_state,\n",
    "    32    887359 34367077552.0  38729.6     87.9                          reward, done)\n",
    "    33                                           \n",
    "    34    887359   21998137.0     24.8      0.1              reward_total[i_episode]+=reward\n",
    "    35                                           \n",
    "    36    887359 3758990705.0   4236.2      9.6              qnet_agent.optimize()\n",
    "    37                                           \n",
    "    38    887359    2534957.0      2.9      0.0              state=new_state\n",
    "    39                                                   \n",
    "    40                                                   \n",
    "    41    887359    1101282.0      1.2      0.0              if done:\n",
    "    42      5000      25283.0      5.1      0.0                  steps_total[i_episode]=step\n",
    "    43                                           \n",
    "    44      5000       7108.0      1.4      0.0                  if i_episode>100:\n",
    "    45      4899     347613.0     71.0      0.0                      mean_reward_100 = np.sum(reward_total[i_episode-100:i_episode])/100\n",
    "    46                                           \n",
    "    47      4899      17965.0      3.7      0.0                      if (mean_reward_100 > score_to_solve and solved == False):\n",
    "    48                                                                   print(\"SOLVED! After %i episodes \" % i_episode)\n",
    "    49                                                                   solved_after = i_episode\n",
    "    50                                                                   solved = True\n",
    "    51                                           \n",
    "    52      5000       7881.0      1.6      0.0                  if (i_episode % report_interval == 0 and i_episode>1):\n",
    "    53         4       2176.0    544.0      0.0                      print(\"**** Episode  {} **** \".format(i_episode))\n",
    "    54         4       1841.0    460.2      0.0                      recent_avg_reward=np.average(reward_total[i_episode-report_interval:i_episode])\n",
    "    55         4        289.0     72.2      0.0                      print(\"Recent average reward: {}\".format(recent_avg_reward))\n",
    "    56         4          8.0      2.0      0.0                      if i_episode>100:\n",
    "    57         4        189.0     47.2      0.0                          print(\"Reward over last 100: {}\".format(mean_reward_100))\n",
    "    58         4        262.0     65.5      0.0                      full_avg_so_far=np.average(reward_total[:i_episode])\n",
    "    59         4        199.0     49.8      0.0                      print(\"Average over all episodes so far: {}\".format(full_avg_so_far))\n",
    "    60         4        186.0     46.5      0.0                      print(\"epsilon: {}\".format(epsilon))\n",
    "    61                                           \n",
    "    62                                                               #print(\"Episode {} finished after: {}\".format(i_episode,step))\n",
    "    63      5000       6117.0      1.2      0.0                  break\n",
    "    64                                           \n",
    "    65         1          1.0      1.0      0.0      if solved:\n",
    "    66                                                   print(\"Solved after %i episodes\" % solved_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(1,figsize=[12,5])\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(rewards_total)), rewards_total,alpha=0.6, color='green')\n",
    "#plt.plot(rewards_total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=[12,5])\n",
    "plt.title(\"Steps to finish episode\")\n",
    "plt.plot(steps_total[:frames_total])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
